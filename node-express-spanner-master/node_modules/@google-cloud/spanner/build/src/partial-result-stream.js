/*!
 * Copyright 2016 Google Inc. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
'use strict';
Object.defineProperty(exports, "__esModule", { value: true });
const common_grpc_1 = require("@google-cloud/common-grpc");
const checkpointStream = require("checkpoint-stream");
const eventsIntercept = require("events-intercept");
const is = require("is");
const mergeStream = require("merge-stream");
const stream_1 = require("stream");
const streamEvents = require("stream-events");
const codec_1 = require("./codec");
/**
 * The PartialResultStream transforms partial result set objects into Row
 * objects.
 *
 * @class
 * @extends {Transform}
 *
 * @param {RowOptions} [options] The row options.
 */
class PartialResultStream extends stream_1.Transform {
    constructor(options = {}) {
        super({ objectMode: true });
        this._destroyed = false;
        this._options = options;
        this._values = [];
    }
    /**
     * Destroys the stream.
     *
     * @param {Error} [err] Optional error to destroy stream with.
     */
    destroy(err) {
        if (this._destroyed) {
            return;
        }
        this._destroyed = true;
        process.nextTick(() => {
            if (err) {
                this.emit('error', err);
            }
            this.emit('close');
        });
    }
    /**
     * Processes each chunk.
     *
     * @private
     *
     * @param {object} chunk The partial result set.
     * @param {string} encoding Chunk encoding (Not used in object streams).
     * @param {function} next Function to be called upon completion.
     */
    _transform(chunk, enc, next) {
        this.emit('response', chunk);
        if (chunk.stats) {
            this.emit('stats', chunk.stats);
        }
        if (!this._fields && chunk.metadata) {
            this._fields = chunk.metadata.rowType.fields;
        }
        if (!is.empty(chunk.values)) {
            this._addChunk(chunk);
        }
        next();
    }
    /**
     * Manages any chunked values.
     *
     * @private
     *
     * @param {object} chunk The partial result set.
     */
    _addChunk(chunk) {
        const values = chunk.values.map(common_grpc_1.Service.decodeValue_);
        // If we have a chunk to merge, merge the values now.
        if (this._pendingValue) {
            const currentField = this._values.length % this._fields.length;
            const field = this._fields[currentField];
            const merged = PartialResultStream.merge(field.type, this._pendingValue, values.shift());
            values.unshift(...merged);
            delete this._pendingValue;
        }
        // If the chunk is chunked, store the last value for merging with the next
        // chunk to be processed.
        if (chunk.chunkedValue) {
            this._pendingValue = values.pop();
        }
        values.forEach(value => this._addValue(value));
    }
    /**
     * Manages complete values, pushing a completed row into the stream once all
     * values have been received.
     *
     * @private
     *
     * @param {*} value The complete value.
     */
    _addValue(value) {
        const values = this._values;
        values.push(value);
        if (values.length !== this._fields.length) {
            return;
        }
        this._values = [];
        const row = this._createRow(values);
        if (this._options.json) {
            this.push(row.toJSON(this._options.jsonOptions));
            return;
        }
        this.push(row);
    }
    /**
     * Converts an array of values into a row.
     *
     * @private
     *
     * @param {Array.<*>} values The row values.
     * @returns {Row}
     */
    _createRow(values) {
        const fields = values.map((value, index) => {
            const { name, type } = this._fields[index];
            return { name, value: codec_1.codec.decode(value, type) };
        });
        Object.defineProperty(fields, 'toJSON', {
            value: (options) => {
                return codec_1.codec.convertFieldsToJson(fields, options);
            }
        });
        return fields;
    }
    /**
     * Attempts to merge chunked values together.
     *
     * @static
     * @private
     *
     * @param {object} type The value type.
     * @param {*} head The head of the combined value.
     * @param {*} tail The tail of the combined value.
     * @returns {Array.<*>}
     */
    // tslint:disable-next-line no-any
    static merge(type, head, tail) {
        if (type.code === "ARRAY" /* ARRAY */ || type.code === "STRUCT" /* STRUCT */) {
            return [PartialResultStream.mergeLists(type, head, tail)];
        }
        if (is.string(head) && is.string(tail)) {
            return [head + tail];
        }
        return [head, tail];
    }
    /**
     * Attempts to merge chunked lists together.
     *
     * @static
     * @private
     *
     * @param {object} type The list type.
     * @param {Array.<*>} head The beginning of the list.
     * @param {Array.<*>} tail The end of the list.
     * @returns {Array.<*>}
     */
    static mergeLists(type, head, tail) {
        let listType;
        if (type.code === 'ARRAY') {
            listType = type.arrayElementType;
        }
        else {
            listType = type.structType.fields[head.length - 1].type;
        }
        const merged = PartialResultStream.merge(listType, head.pop(), tail.shift());
        return [...head, ...merged, ...tail];
    }
}
exports.PartialResultStream = PartialResultStream;
/**
 * Rows returned from queries may be chunked, requiring them to be stitched
 * together. This function returns a stream that will properly assemble these
 * rows, as well as retry after an error. Rows are only emitted if they hit a
 * "checkpoint", which is when a `resumeToken` is returned from the API. Without
 * that token, it's unsafe for the query to be retried, as we wouldn't want to
 * emit the same data multiple times.
 *
 * @private
 *
 * @param {RequestFunction} requestFn The function that makes an API request. It
 *     will receive one argument, `resumeToken`, which should be used however is
 *     necessary to send to the API for additional requests.
 * @param {RowOptions} [options] Options for formatting rows.
 * @returns {PartialResultStream}
 */
function partialResultStream(requestFn, options) {
    let lastResumeToken;
    // mergeStream allows multiple streams to be connected into one. This is good;
    // if we need to retry a request and pipe more data to the user's stream.
    const requestsStream = mergeStream();
    const userStream = streamEvents(new PartialResultStream(options));
    const batchAndSplitOnTokenStream = checkpointStream.obj({
        maxQueued: 10,
        isCheckpointFn: (row) => {
            return is.defined(row.resumeToken);
        }
    });
    const makeRequest = () => {
        requestsStream.add(requestFn(lastResumeToken));
    };
    const retry = (err) => {
        if (!lastResumeToken) {
            // We won't retry the request, so this will flush any rows the
            // checkpoint stream has queued. After that, we will destroy the
            // user's stream with the same error.
            setImmediate(() => batchAndSplitOnTokenStream.destroy(err));
            return;
        }
        // We're going to retry from where we left off.
        // Empty queued rows on the checkpoint stream (will not emit them to user).
        batchAndSplitOnTokenStream.reset();
        makeRequest();
    };
    userStream.once('reading', makeRequest);
    eventsIntercept.patch(requestsStream);
    // need types for events-intercept
    // tslint:disable-next-line no-any
    requestsStream.intercept('error', retry);
    return requestsStream
        .pipe(batchAndSplitOnTokenStream)
        // If we get this error, the checkpoint stream has flushed any rows
        // it had queued. We can now destroy the user's stream, as our retry
        // attempts are over.
        .on('error', (err) => userStream.destroy(err))
        .on('checkpoint', (row) => {
        lastResumeToken = row.resumeToken;
    })
        .pipe(userStream);
}
exports.partialResultStream = partialResultStream;
//# sourceMappingURL=partial-result-stream.js.map